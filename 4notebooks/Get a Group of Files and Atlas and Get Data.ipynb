{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from metatlas import metatlas_objects as metob\n",
    "from metatlas import h5_query as h5q\n",
    "from metatlas import gui as mgui\n",
    "\n",
    "import qgrid\n",
    "import metatlas_get_data_helper_fun as ma_data #look at it\n",
    "import pandas as pd\n",
    "import os\n",
    "import tables\n",
    "import pickle\n",
    "\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mgui.show_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "#Select the group\n",
    "temp_group = metob.retrieve('Groups', name = '%_LS_%',username='*')\n",
    "print len(temp_group)\n",
    "# print temp_group\n",
    "group = []\n",
    "for i,g in enumerate(temp_group):\n",
    "    if len(g.items) > 0:\n",
    "        group.append(g)\n",
    "\n",
    "mgui.edit_objects(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20151130_LS_Negative_Hilic_QExactive_Archetypes 2015-11-30 20:30:58\n",
      "1 20151130_LS_Positive_Hilic_QExactive_Archetypes_ISTDs 2015-12-01 00:57:46\n",
      "2 20151130_LS_Negative_Hilic_QExactive_Archetypes_ISTDs 2015-12-01 00:59:23\n",
      "3 20151130_LS_Positive_Hilic_QExactive_Archetypes 2015-12-14 19:00:01\n"
     ]
    }
   ],
   "source": [
    "#Select the atlas\n",
    "atlas = metob.retrieve('Atlas',name = '%_LS_%',username='*')\n",
    "# mgui.edit_objects(atlas)\n",
    "# len(atlas)\n",
    "# atlas\n",
    "from datetime import datetime, date\n",
    "\n",
    "for i,a in enumerate(atlas):\n",
    "    print i, a.name,  datetime.utcfromtimestamp(a.last_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myAtlas = atlas[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compound_list = []\n",
    "for i in range(len(myAtlas.compound_identifications)):\n",
    "    if myAtlas.compound_identifications[i].compound:\n",
    "        compound_list.append(myAtlas.compound_identifications[i].compound[0].name)\n",
    "    else:\n",
    "        compound_list.append(myAtlas.compound_identifications[i].name)\n",
    "\n",
    "cols = ['inchi',\n",
    " 'mono_isotopic_molecular_weight',\n",
    " 'creation_time',\n",
    " 'description',\n",
    " 'formula',\n",
    " 'functional_sets',\n",
    " 'last_modified',\n",
    " 'reference_xrefs',\n",
    " 'synonyms',\n",
    " 'unique_id',\n",
    " 'url',\n",
    " 'username']\n",
    "    \n",
    "# print myAtlas[0].compound_identifications[0].compound\n",
    "atlas_export = pd.DataFrame( index=compound_list, columns=cols)\n",
    "\n",
    "atlas_export['name'] = compound_list\n",
    "atlas_export.set_index('name',drop=True)\n",
    "for i in range(len(myAtlas.compound_identifications)):\n",
    "    if myAtlas.compound_identifications[i].compound:\n",
    "        n = myAtlas.compound_identifications[i].compound[0].name\n",
    "    else:\n",
    "        n = myAtlas.compound_identifications[i].name\n",
    "    if myAtlas.compound_identifications[i].compound:\n",
    "        for c in cols:\n",
    "                g = getattr(myAtlas.compound_identifications[i].compound[0],c)\n",
    "                if g:\n",
    "                    atlas_export.ix[n,c] = getattr(myAtlas.compound_identifications[i].compound[0],c)\n",
    "    atlas_export.ix[n, 'label'] = myAtlas.compound_identifications[i].name\n",
    "    atlas_export.ix[n,'rt_min'] = myAtlas.compound_identifications[i].rt_references[0].rt_min\n",
    "    atlas_export.ix[n,'rt_max'] = myAtlas.compound_identifications[i].rt_references[0].rt_max\n",
    "    atlas_export.ix[n,'rt_peak'] = myAtlas.compound_identifications[i].rt_references[0].rt_peak\n",
    "    atlas_export.ix[n,'mz'] = myAtlas.compound_identifications[i].mz_references[0].mz\n",
    "    atlas_export.ix[n,'mz_tolerance'] = myAtlas.compound_identifications[i].mz_references[0].mz_tolerance\n",
    "    atlas_export.ix[n,'polarity'] = myAtlas.compound_identifications[i].mz_references[0].detected_polarity\n",
    "atlas_export.to_csv('kate_atlas_uptake_pos.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 27 /global/project/projectdirs/metatlas/raw_data/katezh/20160119_KZ_HILIC_Avena_exu_uptake/20160119_pHILIC___POS_MSMS_KZ_HA20_A_Nocardioides_sp_URHA0020______Run45.h5\n",
      "0"
     ]
    }
   ],
   "source": [
    "# get and pickle everything This is MSMS, raw MS1 datapoints, compound, group info, and file info\n",
    "# combine positive and negative mode atlas, by join atlases together vs two compound references\n",
    "# typically file-groups are NOT split by polarity, files with un-matched polarity will be discarded for analysis of an identification\n",
    "from metatlas import h5_query as h5q\n",
    "import os\n",
    "import tables\n",
    "import dill\n",
    "ma_data = reload(ma_data)\n",
    "data = []\n",
    "for i,treatment_groups in enumerate(group):\n",
    "    for j in range(len(treatment_groups.items)):\n",
    "        myFile = treatment_groups.items[j].hdf5_file\n",
    "#         try:\n",
    "#             rt_reference_index = int(treatment_groups.name[-1]) - 1\n",
    "#         except:\n",
    "#             rt_reference_index = 3\n",
    "        print i,len(group),myFile\n",
    "        row = []\n",
    "        for compound in myAtlas.compound_identifications:\n",
    "            result = {}\n",
    "            result['lcmsrun'] = treatment_groups.items[j]\n",
    "            result['group'] = treatment_groups\n",
    "            result['identification'] = compound\n",
    "            result['data'] = ma_data.get_data_for_a_compound(compound.mz_references[0],\n",
    "                                    compound.rt_references[0],\n",
    "                                    [ 'ms1_summary', 'eic', 'msms' ],\n",
    "                                    myFile,0.2)\n",
    "#                 print result['data']['ms1_summary']\n",
    "            row.append(result)\n",
    "        data.append(row)\n",
    "with open('20160119_KZ_Positive_QE_HILIC_Avena_Uptake.pkl','w') as f:\n",
    "    dill.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var nb = IPython.notebook;\n",
       "var kernel = IPython.notebook.kernel;\n",
       "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var nb = IPython.notebook;\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://nbviewer.ipython.org/url/portal.nersc.gov/project/openmsi/Get a Group of Files and Atlas and Get Data.ipynb?flush_cache=true\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filename = os.path.basename(NOTEBOOK_FULL_PATH)\n",
    "%system cp $filename /project/projectdirs/openmsi/www/\n",
    "temp = '%s/%s'%('/project/projectdirs/openmsi/www',filename)\n",
    "%system chmod 775 $temp\n",
    "print 'http://nbviewer.ipython.org/url/portal.nersc.gov/project/openmsi/%s?flush_cache=true'%filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helpful pandas hints for commands\n",
    "# df\n",
    "# print df.keys()\n",
    "# df.loc[0,'name']\n",
    "# df.filter(regex = 'name')\n",
    "# df.iloc[0]\n",
    "# for x in df.index:\n",
    "#     print df.name[x]\n",
    "#     if not metob.retrieve('Compounds',name=df.name[x]):\n",
    "#         print df.name[x], \"is not in database\"\n",
    "#     else:\n",
    "#         print df.name[x], \"Success\"\n",
    "\n",
    "#         \n",
    "#     df = df.append(data)\n",
    "#     print df.iloc[x,0]\n",
    "#     print df.iloc[x]\n",
    "#     print df.name[x]\n",
    "# df.ix[(df['name']=='Adenine') == True]['mz']\n",
    "# df.ix[(df['name']=='Adenine') == True]\n",
    "# df.name.str.contains('Ad')\n",
    "# df.name.str.contains('Ad').tolist()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.104074    2.104074    2.104074  ...,  11.5003891  11.5003891\n",
      "  11.5003891]\n"
     ]
    }
   ],
   "source": [
    "# files = metob.retrieve('lcmsrun',name='%Actino%')\n",
    "import numpy as np\n",
    "my_run = metob.retrieve('lcmsrun', hdf5_file='%20150510_C18_POS_MSMS_HE08-3%', username='*')\n",
    "my_run\n",
    "# for f in files:\n",
    "#     print f.hdf5_file\n",
    "with tables.open_file(my_run[0].hdf5_file) as fid:\n",
    "    data = h5q.get_data(fid,2,1,min_rt = 2.1)#,max_rt = 17.9,min_precursor_MZ=633.12,max_precursor_MZ = 633.2)\n",
    "print data['rt']\n",
    "prt,pmz = get_unique_scan_data(data)\n",
    "rt_cutoff = 0.23\n",
    "mz_cutoff = 0.05\n",
    "list_of_prt,list_of_pmz = get_non_redundant_precursor_list(prt,pmz,rt_cutoff,mz_cutoff)\n",
    "#setup data format for searching\n",
    "pactolus_input = {}\n",
    "pactolus_input['spectra'] = []\n",
    "pactolus_input['precursor_mz'] = []\n",
    "for i,(prt,pmz) in enumerate(zip(list_of_prt,list_of_pmz)):\n",
    "    idx = np.argwhere((data['precursor_MZ'] == pmz) & (data['rt'] == prt )).flatten()\n",
    "    arr = np.array([data['mz'][idx], data['i'][idx]]).T\n",
    "    pactolus_input['spectra'].append(arr)\n",
    "    pactolus_input['precursor_mz'].append(pmz)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# curr_ld_lib_path = ''\n",
    "# os.environ['LD_LIBRARY_PATH'] = curr_ld_lib_path + ':/project/projectdirs/openmsi/jupyterhub_libs/boost_1_55_0/lib' + ':/project/projectdirs/openmsi/jupyterhub_libs/lib'\n",
    "import sys\n",
    "# sys.path.remove('/anaconda/lib/python2.7/site-packages')\n",
    "sys.path.append('/global/project/projectdirs/openmsi/jupyterhub_libs/anaconda/lib/python2.7/site-packages')\n",
    "\n",
    "# sys.path.insert(0,'/global/project/projectdirs/metatlas/anaconda/lib/python2.7/site-packages' )\n",
    "\n",
    "\n",
    "sys.path.append('/project/projectdirs/openmsi/projects/meta-iq/pactolus/pactolus')\n",
    "\n",
    "import score_frag_dag\n",
    "\n",
    "\n",
    "pos_mode_neutralizations = [-1.00727646677, -(1.00727646677+1.00782504), +5.4857990946e-4,]\n",
    "neg_mode_neutralizations = [-el for el in pos_mode_neutralizations]\n",
    "\n",
    "# make lookup table\n",
    "# path_to_trees = '/project/projectdirs/openmsi/projects/pactolus_trees/'\n",
    "# all_my_h5_files = glob.glob('/project/projectdirs/openmsi/projects/pactolus_trees/*_hdf5_5_*.h5')\n",
    "\n",
    "path_to_trees = '/project/projectdirs/openmsi/projects/ben_trees/'\n",
    "all_my_h5_files = glob.glob('/project/projectdirs/openmsi/projects/ben_trees/*_hdf5_5_*.h5')\n",
    "\n",
    "my_tree_filename = 'metacyc_max_depth_5'\n",
    "\n",
    "if not os.path.isfile(os.path.join(path_to_trees, my_tree_filename + '.npy')):\n",
    "    score_frag_dag.make_file_lookup_table_by_MS1_mass(all_my_h5_files, \n",
    "                                                      path=path_to_trees, \n",
    "                                                      save_result='metacyc_max_depth_5')\n",
    "\n",
    "maxdepth_5_table = os.path.join(path_to_trees, my_tree_filename + '.npy')\n",
    "\n",
    "params = {'file_lookup_table': maxdepth_5_table,\n",
    "          'ms1_mass_tol': 0.05,\n",
    "          'ms2_mass_tol': 0.05,\n",
    "          'neutralizations': pos_mode_neutralizations,\n",
    "          'max_depth': 5,\n",
    "              }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580\n"
     ]
    }
   ],
   "source": [
    "print len(pactolus_input['spectra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00915908813477 0\n",
      "0.225470066071 31\n",
      "13.8581519127 24\n",
      "0.199229955673 29\n",
      "0.205362796783 13\n",
      "0.293752908707 37\n",
      "1.79723000526 133\n",
      "0.200758218765 28\n",
      "0.278684139252 48\n",
      "0.00717997550964 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in range(10):\n",
    "    start = time.time()\n",
    "    foo = score_frag_dag.score_scan_list_against_trees([pactolus_input['spectra'][i]], [pactolus_input['precursor_mz'][i]], params)\n",
    "    stop = time.time()\n",
    "    print stop - start, np.sum(foo>0)\n",
    "# np.argmax(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metatlas_molecules = np.load(maxdepth_5_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13190,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metatlas_molecules.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 13190)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_db = '/project/projectdirs/openmsi/projects/meta-iq/pactolus/data/' + 'MetaCyc.mdb'\n",
    "pactolus_results = score_frag_dag.make_pactolus_hit_table(foo, maxdepth_5_table, original_db=my_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for r in pactolus_results:\n",
    "    if len(r)>0:\n",
    "        print r[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
